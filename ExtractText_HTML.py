import re

from bs4 import BeautifulSoup
import os

from Util import get_file_paths, get_file_tokens, write_tokens_to_file

with open('L_2021206EN.01000101.xml.html', 'r', encoding='utf-8') as f:
    html_content = f.read()

soup = BeautifulSoup(html_content, 'html.parser')


def extract_and_write_texts(soup):
    output_dir = 'extracted_texts'
    os.makedirs(output_dir, exist_ok=True)

    valid_code_pattern = re.compile(r'^\d+[A-Z]\d{3}$')  # 0A001, regex generated by chatgpt

    p_tags = soup.find_all('p', class_='oj-normal')

    for p_tag in p_tags:
        code_text = p_tag.get_text(strip=True)
        # Check if this p_tag contains section code ex. 0B001
        if valid_code_pattern.match(code_text):
            # Find the parent <td> to search for subsequent sibling elements containing the description
            parent_td = p_tag.find_parent('td')
            description_texts = [code_text]  # Initialize description texts with the section code itself

            if parent_td:
                # Consider subsequent siblings within the same <td> for the complete description
                for sibling in parent_td.find_next_siblings():
                    description_texts.append(sibling.get_text("\n", strip=True).replace("\xa0", " "))  # Deal with #NBSP

                # Concatenate all collected texts for the section description
                full_description = " ".join(description_texts)

                file_name = f"{code_text}.txt"
                file_path = os.path.join(output_dir, file_name)
                with open(file_path, 'w', encoding='utf-8') as file:
                    file.write(full_description)
                    print(f"Written {code_text} section to {file_path}")
            else:
                print(f"No description found for {code_text}, skipping file creation.")


extract_and_write_texts(soup)

text_files_paths = get_file_paths('./extracted_texts')
files_and_tokens = get_file_tokens(text_files_paths)
write_tokens_to_file(files_and_tokens, 'tokens')
